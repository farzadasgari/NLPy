{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6d6ec2a-fe25-4747-85db-498fffeac7a3",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization\n",
    "\n",
    "Stemming and lemmatization are techniques used to reduce words to their base or root forms. These processes are essential in text preprocessing to improve the efficiency and effectiveness of many NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59110294-58ba-492b-89bf-d15ecafb639f",
   "metadata": {},
   "source": [
    "## Stemming vs. Lemmatization\n",
    "\n",
    "- **Stemming**: Reduces words to their root form by cutting off prefixes or suffixes. This method may produce non-words or stem words that are not actual words in the language.\n",
    "- **Lemmatization**: Reduces words to their base or dictionary form (lemma) by considering the word's context and meaning. This method usually requires a lexical resource and is more accurate but computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59552146-1c8f-4d39-8bd0-a42f1f8e3e99",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9193a1d4-89a9-4030-a8cb-8b1addd9ca1e",
   "metadata": {},
   "source": [
    "### What is Stemming?\n",
    "\n",
    "Stemming is a heuristic process that removes derivational affixes from words. The goal is to reduce words to a common base form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e516e068-a477-4253-935f-b1ee3b43abe1",
   "metadata": {},
   "source": [
    "### Popular Stemming Algorithms\n",
    "\n",
    "1. **Porter Stemmer**: One of the oldest and most widely used stemming algorithms. Applies simple rules to remove common word endings.\n",
    "2. **Snowball Stemmer**: An improved version of the Porter Stemmer. Provides more aggressive stemming than the PorterStemmer.\n",
    "3. **Lancaster Stemmer**: More aggressive than the Porter Stemmer. Even more aggressive, which can be useful or harmful depending on the application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc08ee-255f-4726-b52e-46902ffcd0d4",
   "metadata": {},
   "source": [
    "### Stemming with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a91754d2-3c08-4d53-9f95-6725af35b76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Words: ['running', 'runner', 'runs', 'easily']\n",
      "Porter Stems: ['run', 'runner', 'run', 'easili']\n",
      "Snowball Stems: ['run', 'runner', 'run', 'easili']\n",
      "Lancaster Stems: ['run', 'run', 'run', 'easy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\free\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer\n",
    "\n",
    "# Download the necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define sample text\n",
    "text = \"running runner runs easily\"\n",
    "\n",
    "# Tokenize the text\n",
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Initialize stemmers\n",
    "porter = PorterStemmer()\n",
    "snowball = SnowballStemmer(\"english\")\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "# Apply stemming\n",
    "porter_stems = [porter.stem(word) for word in words]\n",
    "snowball_stems = [snowball.stem(word) for word in words]\n",
    "lancaster_stems = [lancaster.stem(word) for word in words]\n",
    "\n",
    "# Print the results\n",
    "print(\"Original Words:\", words)\n",
    "print(\"Porter Stems:\", porter_stems)\n",
    "print(\"Snowball Stems:\", snowball_stems)\n",
    "print(\"Lancaster Stems:\", lancaster_stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e3419-a757-4d24-949e-dafec7bdf167",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36621eb0-abde-46a1-b39a-00b88d467fcc",
   "metadata": {},
   "source": [
    "### What is Lemmatization?\n",
    "\n",
    "Lemmatization is the process of reducing words to their base or dictionary form (lemma) using vocabulary and morphological analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74146a5-2589-4896-8151-224fb1255ea6",
   "metadata": {},
   "source": [
    "### Lemmatization with NLTK\n",
    "\n",
    "NLTK provides a lemmatizer based on WordNet, a large lexical database of English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43786084-9b28-4a88-8a6b-efa31c693b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\free\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\free\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Words: ['running', 'runner', 'runs', 'easily']\n",
      "Lemmatized Words: ['run', 'runner', 'run', 'easily']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a sample text\n",
    "text = \"running runner runs easily\"\n",
    "\n",
    "# Tokenize the text\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Define a function to get the part of speech for the lemmatizer\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "# Apply lemmatization\n",
    "lemmatized_words = []\n",
    "for word, tag in nltk.pos_tag(words):\n",
    "    wordnet_pos = get_wordnet_pos(tag)\n",
    "    lemmatized_words.append(lemmatizer.lemmatize(word, pos=wordnet_pos))\n",
    "\n",
    "# Print the results\n",
    "print(\"Original Words:\", words)\n",
    "print(\"Lemmatized Words:\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb4edf-4847-4f6d-a45f-25bc88b87f44",
   "metadata": {},
   "source": [
    "## Comparison of Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8f3cbb-9f88-4023-b628-714201ed002f",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "\n",
    "- **Pros**: Faster and simpler.\n",
    "- **Cons**: May produce non-words or inaccurate root forms.\n",
    "\n",
    "### Lemmatization\n",
    "\n",
    "- **Pros**: More accurate, produces valid words.\n",
    "- **Cons**: Slower and requires more resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e3eb30-346f-4c5a-8da0-54c02213bf95",
   "metadata": {},
   "source": [
    "## When to Use Stemming vs. Lemmatization\n",
    "\n",
    "- **Stemming**: Use when speed is critical and the exact meaning of words is less important.\n",
    "- **Lemmatization**: Use when accuracy is crucial and understanding the precise meaning of words is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428b621f-78ae-47dd-a899-c3a5fa4e27bd",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Stemming and lemmatization are vital preprocessing steps in NLP that help in standardizing text by reducing words to their base forms. Choosing between them depends on the specific requirements of your application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
