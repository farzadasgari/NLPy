{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b11297fb-2f5a-4a6f-8750-c46201ef1e73",
   "metadata": {},
   "source": [
    "# Introduction to Natural Language Processing (NLP) with Python\n",
    "\n",
    "Author: **Farzad Asgari**\n",
    "\n",
    "Welcome to the NLPy course! This notebook will introduce `Natural Language Processing (NLP)`, its applications, and an overview of what we will cover in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf1b96e-f1c3-4ab9-b330-48b8ba172e62",
   "metadata": {},
   "source": [
    "## What is Natural Language Processing?\n",
    "\n",
    "Natural Language Processing (NLP) is a subfield of artificial intelligence (AI) focused on the interaction between computers and humans through natural language. It combines aspects of computer science, linguistics, and machine learning to enable machines to understand, interpret, and generate human language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdcd05b-06c3-4227-8820-a47dbbb30865",
   "metadata": {},
   "source": [
    "## Why is NLP Important?\n",
    "\n",
    "NLP is crucial because it allows computers to process and analyze large amounts of natural language data. This capability is essential for various applications that we use daily, such as search engines, translation services, voice-activated assistants, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52993a-b1f4-4041-ba7f-1ca9405f2d63",
   "metadata": {},
   "source": [
    "### Key Applications of NLP:\n",
    "\n",
    "1. **Sentiment Analysis**: Understanding the sentiment or emotion behind a piece of text, such as determining if a product review is positive or negative.\n",
    "2. **Machine Translation**: Translating text from one language to another, like Google Translate.\n",
    "3. **Chatbots and Virtual Assistants**: Enabling computers to interact with humans in a conversational manner, as seen in Siri and Alexa.\n",
    "4. **Text Summarization**: Automatically generating concise summaries of long documents.\n",
    "5. **Speech Recognition**: Converting spoken language into text, used in voice-activated systems.\n",
    "6. **Named Entity Recognition (NER)**: Identifying and classifying entities (like names, dates, and locations) in a text.\n",
    "7. **Language Modeling**: Predicting the next word in a sentence, which is a core component of text generation models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23661fa0-f214-465f-ba37-46d98f47130a",
   "metadata": {},
   "source": [
    "## Course Outline\n",
    "\n",
    "In this course, we will cover the following topics:\n",
    "\n",
    "1. **Introduction to NLP**\n",
    "2. **Text Preprocessing**: Techniques for cleaning and preparing text data.\n",
    "3. **Word Embeddings**: Representing words in a numerical format.\n",
    "4. **Text Classification**: Classifying text into predefined categories.\n",
    "5. **Named Entity Recognition (NER)**\n",
    "6. **Language Models**\n",
    "7. **Topic Modeling**\n",
    "8. **Text Generation**\n",
    "9. **Practical Applications and Projects**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b866f8b4-4a37-486e-b3bb-32747733f025",
   "metadata": {},
   "source": [
    "## Setting Up the Environment\n",
    "\n",
    "Before we dive into the details, let's set up our Python environment with the necessary libraries. Run the following command to install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "813e6077-eeeb-4fc0-9543-8a34d8fa5fdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: nltk in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: spacy in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: gensim in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: scikit-learn in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: seaborn in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: click in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: language-data>=1.2 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
      "Requirement already satisfied: wrapt in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\work\\github\\nlpy\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas nltk spacy gensim scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd02486-844f-41e8-8e90-48f8ae4b8d61",
   "metadata": {},
   "source": [
    "## Must-Known Terminologies in NLP\n",
    "\n",
    "Understanding the fundamental terminologies in NLP is crucial for grasping the concepts and techniques you will encounter in this course. Below are some essential terms:\n",
    "\n",
    "1. **Word**:\n",
    "   - A basic unit of language that carries meaning. Words are the building blocks of text and are typically separated by spaces in written language.\n",
    "\n",
    "2. **Token**:\n",
    "   - A token is a single unit of text, which could be a word, punctuation mark, or even a subword or character, depending on the level of tokenization.\n",
    "\n",
    "3. **Tokenization**:\n",
    "   - The process of breaking down text into individual tokens. Tokenization can occur at different levels, such as word-level (splitting text into words) or character-level (splitting text into characters).\n",
    "\n",
    "4. **Sentence**:\n",
    "   - A sequence of words that expresses a complete thought. In NLP, sentences are often used as the primary unit of analysis for many tasks.\n",
    "\n",
    "5. **Document**:\n",
    "   - A document is a piece of text, such as a sentence, paragraph, or entire article, that represents a single entity for analysis. In NLP tasks, a document is typically a unit of text to be processed.\n",
    "\n",
    "6. **Corpus**:\n",
    "   - A large and structured set of texts. Corpora (plural of corpus) are used for training and evaluating NLP models. They can consist of documents, sentences, or any other form of text.\n",
    "\n",
    "7. **Vocabulary**:\n",
    "   - The set of all unique tokens (words) present in a corpus. It represents the collection of known words that a model can recognize and use.\n",
    "\n",
    "8. **Stopwords**:\n",
    "   - Commonly used words in a language (e.g., \"the\", \"is\", \"in\") that are often filtered out before processing text, as they may not carry significant meaning for certain NLP tasks.\n",
    "\n",
    "9. **Stemming and Lemmatization**:\n",
    "   - **Stemming**: The process of reducing a word to its root form. For example, \"running\" becomes \"run\".\n",
    "   - **Lemmatization**: Similar to stemming but more sophisticated, lemmatization reduces a word to its base or dictionary form (lemma). For example, \"better\" becomes \"good\".\n",
    "\n",
    "10. **Word Vectors**:\n",
    "    - Also known as word embeddings, these are dense vector representations of words in a continuous vector space. Word vectors capture semantic meanings and relationships between words. Popular techniques to generate word vectors include Word2Vec, GloVe, and fastText.\n",
    "\n",
    "11. **Language Model**:\n",
    "    - A model that is trained to understand and generate human language. Language models predict the next word in a sequence based on the previous words, and are used in tasks like text generation, translation, and more.\n",
    "\n",
    "---\n",
    "\n",
    "These terminologies form the foundation of many NLP techniques and concepts that we will explore throughout this course. Understanding them will help you navigate through the materials more effectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
